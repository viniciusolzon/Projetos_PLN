{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Vinicius Freitas Schiavinato Olzon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrícula: 20210026803\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O objetivo deste exercício é treinar e avaliar uma rede neural recorrente (RNN\n",
    "ou LSTM) para classificar um conjunto de dados sobre notícias de acordo com\n",
    "suas categorias.\n",
    "- A rede neural pode ser criada utilizando o PyTorch ou Tensorflow/Keras. A rede\n",
    "neural deve ser avaliada através do cálculo da acurácia (quantidade de acertos\n",
    "dividido pela quantidade total de testes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega as bibliotecas necessárias para puxar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio\n",
    "# %pip install datasets\n",
    "# %pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"okite97/news-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'Category'],\n",
       "        num_rows: 4686\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'Category'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uefa',\n",
       " 'has',\n",
       " 'opened',\n",
       " 'disciplinary',\n",
       " 'proceedings',\n",
       " 'against',\n",
       " 'barcelona',\n",
       " ',',\n",
       " 'juventus',\n",
       " 'and',\n",
       " 'real',\n",
       " 'madrid',\n",
       " 'over',\n",
       " 'their',\n",
       " 'involvement',\n",
       " 'in',\n",
       " 'the',\n",
       " 'proposed',\n",
       " 'european',\n",
       " 'super',\n",
       " 'league',\n",
       " '.']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset['train'][\"Excerpt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list_train = []\n",
    "for i in range(len(dataset['train']['Excerpt'])):\n",
    "    tokens_list_train.append(tokenizer(dataset['train']['Excerpt'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list_test = []\n",
    "for i in range(len(dataset['test']['Excerpt'])):\n",
    "    tokens_list_test.append(tokenizer(dataset['test']['Excerpt'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adiciona as colunas novas de tokens nos dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column(name='tokens', column=tokens_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'] = dataset['test'].add_column(name='tokens', column=tokens_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uefa',\n",
       " 'has',\n",
       " 'opened',\n",
       " 'disciplinary',\n",
       " 'proceedings',\n",
       " 'against',\n",
       " 'barcelona',\n",
       " ',',\n",
       " 'juventus',\n",
       " 'and',\n",
       " 'real',\n",
       " 'madrid',\n",
       " 'over',\n",
       " 'their',\n",
       " 'involvement',\n",
       " 'in',\n",
       " 'the',\n",
       " 'proposed',\n",
       " 'european',\n",
       " 'super',\n",
       " 'league',\n",
       " '.']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['tokens'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab_custom = build_vocab_from_iterator(dataset['train']['tokens'],\n",
    "                                         min_freq=3,\n",
    "                                         specials=['<unk>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens desconhecidos ficarão como índice 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_custom.set_default_index(vocab_custom['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_custom['european']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_custom['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_custom['cleber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4137"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(tokens):\n",
    "  result = []\n",
    "  for token in tokens:\n",
    "    result.append(vocab_custom[token])\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 139, 549, 25, 797, 4, 44, 1, 0]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['that', 'football', 'player', 'is', 'going', 'to', 'be', 'the', 'mvp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 139, 549, 25, 797, 4, 44, 1, 509]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['that', 'football', 'player', 'is', 'going', 'to', 'be', 'the', 'best'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando 'Category' para valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32326/2476905115.py:2: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  categoria_numerico_treino = pd.factorize(dataset['train']['Category'])[0]\n",
      "/tmp/ipykernel_32326/2476905115.py:3: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  categoria_numerico_teste = pd.factorize(dataset['test']['Category'])[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "categoria_numerico_treino = pd.factorize(dataset['train']['Category'])[0]\n",
    "categoria_numerico_teste = pd.factorize(dataset['test']['Category'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sports', 'business', 'politics', 'health', 'politics', 'sports']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['Category'][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(categoria_numerico_treino[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 'politics', 'business', 'health', 'business', 'politics']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['test']['Category'][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(categoria_numerico_teste[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column(name=\"Category\", column=categoria_numerico_treino)\n",
    "dataset['test'] = dataset['test'].add_column(name=\"Category\", column=categoria_numerico_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category'],\n",
       "        num_rows: 4686\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 2, 0]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['Category'][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2id(row):\n",
    "    row['tokens_id'] = vocab(row['tokens'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4686/4686 [00:00<00:00, 8568.27 examples/s]\n",
      "Map: 100%|██████████| 828/828 [00:00<00:00, 9841.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category', 'tokens_id'],\n",
       "        num_rows: 4686\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category', 'tokens_id'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uefa', 'has', 'opened', 'disciplinary', 'proceedings', 'against', 'barcelona', ',', 'juventus', 'and', 'real', 'madrid', 'over', 'their', 'involvement', 'in', 'the', 'proposed', 'european', 'super', 'league', '.']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[577, 7, 755, 0, 3008, 64, 229, 2, 465, 10, 210, 196, 41, 36, 3633, 6, 1, 572, 178, 123, 50, 9]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['tokens_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEWSDataset(Dataset):\n",
    "  def __init__(self, dataset):\n",
    "    self.data = dataset['tokens_id']\n",
    "    self.labels = dataset['Category']\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, x):\n",
    "    return torch.tensor(self.data[x]), torch.tensor(self.labels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_news = NEWSDataset(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4686"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category', 'tokens_id'],\n",
       "        num_rows: 4686\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Title', 'Excerpt', 'tokens', 'Category', 'tokens_id'],\n",
       "        num_rows: 828\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_news[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_news[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(NEWSDataset(dataset['train']), shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
